{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xor\n",
    "\n",
    "Now let's try a slightly harder example - the XOR function. Unlike AND or OR, it cannot be solved via a single perceptron, because it is not \"linearly separable\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xor is true (1 in this case) only when one of the inputs is true. If both or neither is true, then the result is false (or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = np.array([\n",
    "    np.array([1, 1]),\n",
    "    np.array([1, 0]),\n",
    "    np.array([0, 1]),\n",
    "    np.array([0, 0])\n",
    "])\n",
    "\n",
    "training_labels = np.array([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(layer_dimensions: List[int]):\n",
    "    parameters = {}\n",
    "    numLayers = len(layer_dimensions)\n",
    "    \n",
    "    for l in range(1, numLayers):\n",
    "        # Initialize weights to a small random number.\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dimensions[l], layer_dimensions[l-1]) * 0.01\n",
    "        # Initialize biases to zero.\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dimensions[l], 1))\n",
    "        \n",
    "        # Ensure that everything looks right.\n",
    "        assert(parameters['W' + str(l)].shape == (layer_dimensions[l], layer_dimensions[l - 1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dimensions[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    The \"linear\" part of a layer's forward propagation.\n",
    "    \n",
    "    Arguments::\n",
    "    A -- Activations from the previous layer.\n",
    "    W -- Weights matrix.\n",
    "    b -- Bias vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input to the activation function.\n",
    "    Z = np.dot(W, A) + b\n",
    "    # Values we'll need when doing backward propagation.\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    return A, Z\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0, Z)\n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "    A, activation_cache = activation(Z)\n",
    "    \n",
    "    assert(A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Forward propagation for each layer. Each layer is Linear->Relu, except\n",
    "    for the output layer, which is Liner->Sigmoid.\n",
    "    \"\"\"\n",
    "    \n",
    "    caches = []\n",
    "    # The initial \"previous\" layer is the inputs.\n",
    "    A = X\n",
    "    # The number of layers. Note that we divide by because the `parameters` contains\n",
    "    # weights AND biases for each layer.\n",
    "    numLayers = len(parameters) // 2\n",
    "    \n",
    "    # Relu layers\n",
    "    for l in range(1, numLayers):\n",
    "        A_prev = A\n",
    "        W = parameters['W' + str(l)]\n",
    "        b = parameters['b' + str(l)]\n",
    "        A, cache = linear_activation_forward(A_prev, W, b, relu)\n",
    "        caches.append(cache)\n",
    "        \n",
    "    # Sigmoid layer\n",
    "    W = parameters['W' + str(numLayers)]\n",
    "    b = parameters['b' + str(numLayers)]\n",
    "    Yhat, cache = linear_activation_forward(A, W, b, sigmoid)\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(Yhat.shape == (1, X.shape[1]))\n",
    "    \n",
    "    return Yhat, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Yhat, Y):\n",
    "    \"\"\"\n",
    "    Compute the cross-entropy cost.\n",
    "    \n",
    "    Arguments:\n",
    "    Yhat -- Probability vector corresponding to label predictions.\n",
    "    Y -- Actual label vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    numExamples = Y.shape[1]\n",
    "    \n",
    "    cost = -(1 / numExamples) * np.sum(np.multiply(Y, np.log(Yhat)) + np.multiply(1 - Y, np.log(1 - Yhat)))\n",
    "    return np.squeeze(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Linear part of backwards propagation.\n",
    "    \n",
    "    Arguments:\n",
    "    dZ -- Derivative (gradient) of the cost with respect to the linear output of the current layer.\n",
    "    cache -- Tuple of values (A_prev, W, b) coming from forward propagation of the current layer.\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Derivative of the cost with respect to the activation of the previous layer.\n",
    "    dW -- Derivative of the cost with respect to the weights of the current layer.\n",
    "    db -- Derivative of the cost with respect to the bias of the current layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    A_prev, W, b = cache\n",
    "    numExamples = A_prev.shape[1]\n",
    "    \n",
    "    dA_prev = np.dot(np.transpose(W), dZ)\n",
    "    dW = (1 / numExamples) * np.dot(dZ, np.transpose(A_prev))\n",
    "    db = (1 / numExamples) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation_backward):\n",
    "    linear_cache, activation_cache = cache\n",
    "    dZ = activation_backward(dA, activation_cache)\n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, Z):\n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    dZ = dA * s * (1 - s)\n",
    "    return dZ\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    \n",
    "    # When Z <= 0, dZ should be 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_backward(Yhat, Y, caches):\n",
    "    \"\"\"\n",
    "    Backward propagation for each layer (starts with the last layer).\n",
    "    \n",
    "    Arguments:\n",
    "    Yhat -- Probability vector. The output of forward propagation.\n",
    "    Y -- Labels.\n",
    "    caches -- List of caches captured from each forward propagation step.\n",
    "    \"\"\"\n",
    "    \n",
    "    gradients = {}\n",
    "    num_layers = len(caches)\n",
    "    num_examples = Yhat.shape[1]\n",
    "    Y = Y.reshape(Yhat.shape)\n",
    "    \n",
    "    # Derivative of the cost with respect to Yhat.\n",
    "    dYhat = -(np.divide(Y, Yhat) - np.divide(1 - Y, 1 - Yhat))\n",
    "    \n",
    "    # The last (sigmoid) layer.\n",
    "    current_cache = caches[num_layers - 1]\n",
    "    gradients['dA' + str(num_layers)], gradients['dW' + str(num_layers)], gradients['db' + str(num_layers)] = linear_activation_backward(dYhat, current_cache, sigmoid_backward)\n",
    "    \n",
    "    for l in reversed(range(num_layers - 1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(gradients[\"dA\" + str(l + 2)], current_cache, relu_backward)\n",
    "        gradients['dA' + str(l + 1)] = dA_prev_temp\n",
    "        gradients['dW' + str(l + 1)] = dW_temp\n",
    "        gradients['db' + str(l + 1)] = db_temp\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(parameters, gradients, learning_rate):\n",
    "    num_layers = len(parameters) // 2\n",
    "    for l in range(num_layers):\n",
    "        parameters['W' + str(l + 1)] = parameters['W' + str(l + 1)] - learning_rate * gradients['dW' + str(l + 1)]\n",
    "        parameters['b' + str(l + 1)] = parameters['b' + str(l + 1)] - learning_rate * gradients['db' + str(l + 1)]\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layer_dimensions, learning_rate = 0.0075, num_iterations = 3000):\n",
    "    costs = []\n",
    "    parameters = initialize_params(layer_dimensions)\n",
    "    \n",
    "    # Gradient descent\n",
    "    for i in range(0, num_iterations):\n",
    "        # Forward propagation\n",
    "        Yhat, caches = model_forward(X, parameters)\n",
    "        \n",
    "        # Compute cost\n",
    "        cost = compute_cost(Yhat, Y)\n",
    "        \n",
    "        # Backward propagation\n",
    "        gradients = model_backward(Yhat, Y, caches)\n",
    "        \n",
    "        # Update parameters\n",
    "        parameters = update_params(parameters, gradients, learning_rate)\n",
    "        \n",
    "        costs.append(cost)\n",
    "        \n",
    "    # Plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = model(training_inputs.T, training_labels.reshape(1, -1), [2, 3, 1], learning_rate = 0.05, num_iterations = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    num_examples = X.shape[1]\n",
    "    num_layers = len(parameters)\n",
    "    predictions = np.zeros((1, num_examples))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probabilities, caches = model_forward(X, parameters)\n",
    "    \n",
    "    # Convert probabilities to 0/1\n",
    "    for i in range(0, probabilities.shape[1]):\n",
    "        if probabilities[0, i] > 0.5:\n",
    "            predictions[0, i] = 1\n",
    "        else:\n",
    "            predictions[0, i] = 0\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "predict_on = np.array([\n",
    "    np.array([1, 1]),\n",
    "    np.array([1, 0]),\n",
    "    np.array([0, 1]),\n",
    "    np.array([0, 0])\n",
    "])\n",
    "\n",
    "predictions = predict(predict_on.T, parameters)\n",
    "\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
